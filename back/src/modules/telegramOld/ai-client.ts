/**
 * AI å®¢æˆ·ç«¯é…ç½® - ç”¨äºèŠå¤©åŠŸèƒ½
 * 
 * æä¾›ç»Ÿä¸€çš„ AI å®¢æˆ·ç«¯æ¥å£ï¼Œæ”¯æŒçœŸå® API å’Œæ¨¡æ‹Ÿæ¨¡å¼
 * å¢å¼ºæ”¯æŒæµå¼å“åº”å’Œæ›´å¥½çš„é”™è¯¯å¤„ç†
 */
import { MockOpenAI } from './mock-llm.js';
import EventEmitter from 'events';

// å£°æ˜å…¨å±€ç©ºé—´
declare global {
  namespace NodeJS {
    interface Global {
      openaiClient: OpenAIClient | MockOpenAI;
    }
  }
}

/**
 * å“åº”å¤„ç†å™¨ç±»å‹å®šä¹‰
 */
interface ResponseHandler {
  onMessage: (content: string) => void;
  onComplete: (fullResponse: any) => void;
  onError: (error: Error) => void;
}

/**
 * è‡ªå®šä¹‰ OpenAI å®¢æˆ·ç«¯ç±» - ä¸éœ€è¦å®‰è£… openai åŒ…
 */
export class OpenAIClient {
  baseUrl: string;
  apiKey: string;
  model: string;
  timeout: number;
  retryAttempts: number;

  constructor() {
    this.baseUrl = 'https://ark.cn-beijing.volces.com/api/v3';
    this.apiKey = process.env.TELEGRAM_CHAT_AI_API || '';
    this.model = process.env.TELEGRAM_CHAT_AI_ENDPOINT || '';
    this.timeout = 30000; // 30ç§’è¶…æ—¶
    this.retryAttempts = 1; // é‡è¯•æ¬¡æ•°
  }

  chat = {
    completions: {
      create: async (params: any) => {
        try {
          console.log(`[OpenAIClient] å‘é€è¯·æ±‚åˆ° ${this.baseUrl}/chat/completions`);
          
          // å¤„ç†æµå¼å“åº”
          if (params.stream === true) {
            return this.createStreamingCompletion(params);
          }
          
          // æ ‡å‡†å“åº”
          return await this.createStandardCompletion(params);
        } catch (error: any) {
          console.error("[OpenAIClient] APIè°ƒç”¨å¤±è´¥:", error.message);
          throw error;
        }
      },
    },
  };
  
  /**
   * åˆ›å»ºæ ‡å‡†å®Œæˆè¯·æ±‚
   */
  private async createStandardCompletion(params: any): Promise<any> {
    let attempts = 0;
    let lastError: Error | null = null;
    
    while (attempts <= this.retryAttempts) {
      try {
        const response = await fetch(`${this.baseUrl}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${this.apiKey}`,
          },
          body: JSON.stringify({
            ...params,
            model: params.model || this.model,
            stream: false
          }),
          signal: AbortSignal.timeout(this.timeout)
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€: ${response.status}ï¼Œé”™è¯¯: ${errorText}`);
        }

        return await response.json();
      } catch (error: any) {
        lastError = error;
        attempts++;
        
        if (attempts <= this.retryAttempts) {
          console.log(`[OpenAIClient] é‡è¯•è¯·æ±‚ ${attempts}/${this.retryAttempts}`);
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
      }
    }
    
    throw lastError || new Error('æœªçŸ¥é”™è¯¯');
  }
  
  /**
   * åˆ›å»ºæµå¼å®Œæˆè¯·æ±‚
   */
  private createStreamingCompletion(params: any): any {
    const emitter = new EventEmitter();
    
    // åˆ›å»ºå¯¹è±¡å°è£…æµå¼å¤„ç†
    const stream = {
      on: (event: string, callback: Function) => {
        emitter.on(event, callback as (...args: any[]) => void);
        return stream;
      },
      removeAllListeners: () => {
        emitter.removeAllListeners();
        return stream;
      },
      controller: new AbortController()
    };
    
    // å¼€å§‹å¤„ç†
    (async () => {
      try {
        const response = await fetch(`${this.baseUrl}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${this.apiKey}`,
            "Accept": "text/event-stream"
          },
          body: JSON.stringify({
            ...params,
            model: params.model || this.model,
            stream: true
          }),
          signal: stream.controller.signal
        });
        
        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€: ${response.status}ï¼Œé”™è¯¯: ${errorText}`);
        }
        
        if (!response.body) {
          throw new Error('å“åº”ä½“ä¸ºç©º');
        }
        
        // å¤„ç†æµå¼å“åº”
        const reader = response.body.getReader();
        const decoder = new TextDecoder("utf-8");
        let buffer = '';
        
        while (true) {
          const { done, value } = await reader.read();
          if (done) {
            break;
          }
          
          buffer += decoder.decode(value, { stream: true });
          
          // å¤„ç†ç¼“å†²åŒºä¸­çš„æ‰€æœ‰è¡Œ
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';
          
          for (const line of lines) {
            if (line.startsWith('data: ') && line !== 'data: [DONE]') {
              try {
                const data = JSON.parse(line.substring(6));
                emitter.emit('data', data);
              } catch (e) {
                console.error('[OpenAIClient] è§£ææµå¼æ•°æ®å¤±è´¥:', e);
              }
            } else if (line === 'data: [DONE]') {
              emitter.emit('end');
              return;
            }
          }
        }
        
        emitter.emit('end');
        
      } catch (error: any) {
        console.error('[OpenAIClient] æµå¼å¤„ç†é”™è¯¯:', error);
        emitter.emit('error', error);
      }
    })();
    
    return stream;
  }

  /**
   * æµ‹è¯•è¿æ¥æ˜¯å¦æ­£å¸¸
   */
  async testConnection(): Promise<boolean> {
    try {
      const response = await this.chat.completions.create({
        messages: [{ role: 'user', content: 'æµ‹è¯•' }],
        model: this.model,
        max_tokens: 10
      });
      return !!response.choices;
    } catch (error) {
      console.error("[OpenAIClient] è¿æ¥æµ‹è¯•å¤±è´¥:", error);
      return false;
    }
  }
}

/**
 * åˆ›å»ºæ¨¡æ‹Ÿå®¢æˆ·ç«¯
 */
export function createMockClient() {
  console.log("[AIClient] åˆ›å»ºæ¨¡æ‹Ÿ AI å®¢æˆ·ç«¯");
  return new MockOpenAI({
    apiKey: 'mock-api-key',
    baseURL: 'https://mock-api.com/v1'
  });
}

/**
 * åˆ›å»º AI å®¢æˆ·ç«¯
 */
export const setupAIClient = () => {
  // æ£€æŸ¥ç¯å¢ƒå˜é‡
  const apiKey = process.env.TELEGRAM_CHAT_AI_API;
  const endpoint = process.env.TELEGRAM_CHAT_AI_ENDPOINT;
  
  let aiClient: OpenAIClient | MockOpenAI;
  
  if (apiKey && endpoint) {
    try {
      console.log(`ğŸ¤– åˆå§‹åŒ– AI å®¢æˆ·ç«¯ï¼Œç«¯ç‚¹: ${endpoint}`);
      // åˆ›å»ºè‡ªå®šä¹‰ OpenAI å®¢æˆ·ç«¯
      aiClient = new OpenAIClient();
      console.log("âœ… AI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ");
      console.log(`ğŸ”‘ APIå¯†é’¥å‰4ä½: ${apiKey.substring(0, 4)}...`);
      
      // å¼‚æ­¥æµ‹è¯•è¿æ¥
      setTimeout(async () => {
        const isConnected = await aiClient.testConnection();
        if (!isConnected) {
          console.warn("âš ï¸ AI è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå“åº”");
          const mockClient = createMockClient();
          aiClient = mockClient;
          global.openaiClient = mockClient;
        } else {
          console.log("âœ… AI è¿æ¥æµ‹è¯•æˆåŠŸ");
        }
      }, 1000);
      
    } catch (error) {
      console.error("âŒ AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥:", error);
      aiClient = createMockClient();
    }
  } else {
    console.warn("âš ï¸ AI API ç¯å¢ƒå˜é‡æœªå®Œå…¨è®¾ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿ AI");
    aiClient = createMockClient();
  }
  
  return aiClient;
};

// åˆ›å»º AI å®¢æˆ·ç«¯å®ä¾‹
const aiClient = setupAIClient();

// è®¾ç½®å…¨å±€å˜é‡ï¼Œæ–¹ä¾¿åœ¨å…¶ä»–æ¨¡å—ä¸­è®¿é—®
global.openaiClient = aiClient;

// å¯¼å‡º AI å®¢æˆ·ç«¯ - å¤šç§å¯¼å‡ºæ–¹å¼ï¼Œç¡®ä¿å…¼å®¹æ€§
export { aiClient };
export default aiClient;
